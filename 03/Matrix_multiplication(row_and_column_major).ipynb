{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tyHnyWccEBK7"
      },
      "outputs": [],
      "source": [
        "import torch, os, math, gzip, pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from urllib.request import urlretrieve\n",
        "from pathlib import Path\n",
        "\n",
        "from torch import tensor\n",
        "import torchvision as tv\n",
        "import torchvision.transforms.functional as tvf\n",
        "from torchvision import io\n",
        "from torch.utils.cpp_extension import load_inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Multiplication"
      ],
      "metadata": {
        "id": "mpPBraQi1rBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2d Matrix multiplication"
      ],
      "metadata": {
        "id": "wx9cH_nY1z6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N, M = 50, 75"
      ],
      "metadata": {
        "id": "iNJtara-RiZh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.randn(N, M)\n",
        "B = torch.randn(M, N)\n",
        "C = torch.zeros(N, N, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "LqWwI5NrRtKq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(N):\n",
        "  for j in range(N):\n",
        "    for k in range(M):\n",
        "      C[i,j] += A[i,k] * B[k,j]"
      ],
      "metadata": {
        "id": "Rokq3nJuR5h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mat_mul(A, B):\n",
        "  C = torch.zeros(N, N)\n",
        "  for i in range(N):\n",
        "    for j in range(N):\n",
        "      for k in range(M):\n",
        "        C[i,j] += A[i,k] * B[k,j]\n",
        "  return C"
      ],
      "metadata": {
        "id": "DgJzArEhSbvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "C = mat_mul(A, B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZjNUU4DSr33",
        "outputId": "10371250-83f2-450d-f852-6bc35e469ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30.3 s ¬± 343 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz8oO9AWS9I6",
        "outputId": "536f666e-44cc-4890-f557-b332a256da71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA setup"
      ],
      "metadata": {
        "id": "ADqetDTyI0QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
        "# Get the CUDA capability of the current device\n",
        "if torch.cuda.is_available():\n",
        "    major, minor = torch.cuda.get_device_capability()\n",
        "    # Set the environment variable with the detected architecture\n",
        "    os.environ['TORCH_CUDA_ARCH_LIST'] = f\"{major}.{minor}\"\n",
        "    print(f\"Setting TORCH_CUDA_ARCH_LIST to: {os.environ['TORCH_CUDA_ARCH_LIST']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl1aQr4aIlsk",
        "outputId": "36ae7044-d419-4b05-894c-48776f0e5fb4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting TORCH_CUDA_ARCH_LIST to: 7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q wurlitzer ninja"
      ],
      "metadata": {
        "id": "z2Bdh6gkI7Eg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c9b56d-7a2f-4cc3-cb3b-0f4b5a0e7f04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/422.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext wurlitzer"
      ],
      "metadata": {
        "id": "K6GvgQ28I9Yr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cuda(cuda_src, cpp_src, funcs, opt=False, verbose=False):\n",
        "    return load_inline(cuda_sources=[cuda_src], cpp_sources=[cpp_src], functions=funcs,\n",
        "                       extra_cuda_cflags=[\"-O2\"] if opt else [], verbose=verbose, name=\"inline_ext\")"
      ],
      "metadata": {
        "id": "nV4hODOxJBcr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_begin = r'''\n",
        "#include <torch/extension.h>\n",
        "#include <stdio.h>\n",
        "#include <c10/cuda/CUDAException.h>\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
        "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "hIXPJ9qvJQdM"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## row major matrix mul\n",
        ""
      ],
      "metadata": {
        "id": "IzMw_P6ZuYxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üöÄ CUDA Matrix Multiplication (Row-Major) Kernel\n",
        "\n",
        "This CUDA kernel performs matrix multiplication for **row-major** matrices.\n",
        "\n",
        "#### Matrix Shapes:\n",
        "- `A`: shape (m √ó n)\n",
        "- `B`: shape (n √ó o)\n",
        "- `C = A √ó B`: shape (m √ó o)\n",
        "\n",
        "---\n",
        "\n",
        "#### üß† Kernel Logic\n",
        "```cpp\n",
        "extern \"C\" __global__ void mat_mul_kernel(\n",
        "  float *A, float *B, float *C,\n",
        "  int m, int n, int o)\n",
        "{\n",
        "    int r = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (r < m) {\n",
        "        for (int c = 0; c < o; c++) {\n",
        "            float val = 0.0f;\n",
        "            for (int i = 0; i < n; i++) {\n",
        "                val += A[r * n + i] * B[i * o + c];\n",
        "            }\n",
        "            C[r * o + c] = val;\n",
        "        }\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "SDpeWfzP1f0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src = cuda_begin + r'''\n",
        "\n",
        "extern \"C\" __global__ void mat_mul_kernel(\n",
        "    const float* A, const float* B, float* C,\n",
        "    int m, int n, int o) {\n",
        "\n",
        "    int r = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int c = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (r < m && c < o) {\n",
        "        float val = 0.0f;\n",
        "        for (int i = 0; i < n; ++i) {\n",
        "            val += A[r * n + i] * B[i * o + c];\n",
        "        }\n",
        "        C[r * o + c] = val;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "torch::Tensor mat_mul_row(torch::Tensor A, torch::Tensor B) {\n",
        "    CHECK_INPUT(A);\n",
        "    CHECK_INPUT(B);\n",
        "\n",
        "    int m = A.size(0);\n",
        "    int n = A.size(1);\n",
        "    int o = B.size(1);\n",
        "\n",
        "    auto C = torch::zeros({m, o}, A.options());\n",
        "\n",
        "    dim3 threads(32, 32);\n",
        "    dim3 blocks((o + 31) / 32, (m + 31) / 32);\n",
        "\n",
        "    mat_mul_kernel<<<blocks, threads>>>(\n",
        "        A.data_ptr<float>(),\n",
        "        B.data_ptr<float>(),\n",
        "        C.data_ptr<float>(),\n",
        "        m, n, o);\n",
        "\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "    return C;\n",
        "}\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "gsMUDejsJUGg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpp_src = \"torch::Tensor mat_mul_row(torch::Tensor A, torch::Tensor B);\"\n",
        "module = load_inline(\n",
        "    name=\"inline_ext_v2\",  # üîÅ Force rebuild by changing name\n",
        "    cuda_sources=[cuda_src],\n",
        "    cpp_sources=[cpp_src],\n",
        "    functions=['mat_mul_row'],\n",
        "    extra_cuda_cflags=[\"-O2\"],\n",
        "    verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "GnktrdZ0Z8ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a637e9b-5f69-4082-9308-92eeaf582be1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using /root/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n",
            "The input conditions for extension module inline_ext_v2 have changed. Bumping to version 1 and re-building as inline_ext_v2_v1...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py311_cu124/inline_ext_v2/build.ninja...\n",
            "Building extension module inline_ext_v2_v1...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=inline_ext_v2_v1 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /root/.cache/torch_extensions/py311_cu124/inline_ext_v2/main.cpp -o main.o \n",
            "[2/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=inline_ext_v2_v1 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -O2 -std=c++17 -c /root/.cache/torch_extensions/py311_cu124/inline_ext_v2/cuda.cu -o cuda.cuda.o \n",
            "[3/3] c++ main.o cuda.cuda.o -shared -L/usr/local/lib/python3.11/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o inline_ext_v2_v1.so\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading extension module inline_ext_v2_v1...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c07b443-f565-4527-91c6-348f35c6c544",
        "outputId": "02db790b-6107-4963-b3f2-0ffc8956a7e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__spec__',\n",
              " 'mat_mul_row']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "dir(module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1d659248-5efe-4d41-98ae-66fdedf5e23a"
      },
      "outputs": [],
      "source": [
        "Ac = A.contiguous().cuda()\n",
        "Bc = B.contiguous().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ac.shape, Bc.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbipf9X3MhmI",
        "outputId": "d3404610-71a8-40bd-c133-320b953d7109"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50, 75]), torch.Size([75, 50]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b1c7b73-c867-4d27-805c-750224f9c767",
        "outputId": "298d62e4-9b01-4f34-ce16-15d22801f488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.14 ms, sys: 9.03 ms, total: 10.2 ms\n",
            "Wall time: 23.1 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "C = module.mat_mul_row(Ac, Bc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N, M = 1150, 750"
      ],
      "metadata": {
        "id": "3q9WmqTKbsya"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.randn(N, M)\n",
        "B = torch.randn(M, N)\n",
        "C = torch.zeros(N, N, dtype=torch.float32)\n",
        "Ac = A.contiguous().cuda()\n",
        "Bc = B.contiguous().cuda()"
      ],
      "metadata": {
        "id": "9al7TwMsbsya"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "C = module.mat_mul_row(Ac, Bc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DK52lBTPbx4f",
        "outputId": "47ccb54d-32c6-4a5f-e6a2-257d8de5a60d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.3 ms, sys: 56 ¬µs, total: 6.35 ms\n",
            "Wall time: 6.48 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### üöÄ CUDA Matrix Multiplication (Col-Major) Kernel\n",
        "\n",
        "This CUDA kernel performs matrix multiplication for **col-major** matrices.\n",
        "\n",
        "#### Matrix Shapes:\n",
        "- `A`: shape (m √ó n)\n",
        "- `B`: shape (n √ó o)\n",
        "- `C = A √ó B`: shape (m √ó o)"
      ],
      "metadata": {
        "id": "jbIl80bK1tF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_begin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "AxF88xdo57Yx",
        "outputId": "d5a21a12-2759-4c94-cc85-940d2f3cb30f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#include <torch/extension.h>\\n#include <stdio.h>\\n#include <c10/cuda/CUDAException.h>\\n\\n#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\\n#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\\n#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src_col = cuda_begin + r'''\n",
        "\n",
        "extern \"C\" __global__ void mat_mulC_kernel(\n",
        "  float *A, float *B, float *C,\n",
        "  int m, int n, int o)\n",
        "{\n",
        "\n",
        "    int c = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (c < o) {\n",
        "        for (int r = 0; r < m; r++) {\n",
        "            float val = 0.0f;\n",
        "            for (int i = 0; i < n; i++) {\n",
        "                val += A[r * n + i] * B[i * o + c];\n",
        "            }\n",
        "            C[r * o + c] = val;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int cdiv(unsigned int a, unsigned int b) { return (a + b - 1) / b;}\n",
        "\n",
        "\n",
        "torch::Tensor mat_mul_col(torch::Tensor A, torch::Tensor B) {\n",
        "    CHECK_INPUT(A);\n",
        "    CHECK_INPUT(B);\n",
        "\n",
        "    int m = A.size(0);\n",
        "    int n = A.size(1);\n",
        "    int o = B.size(1);\n",
        "\n",
        "    auto C = torch::zeros({m, o}, A.options());\n",
        "\n",
        "    dim3 threads(32, 32);\n",
        "    dim3 blocks(cdiv(m, threads.x), cdiv(o, threads.y));\n",
        "\n",
        "    mat_mulC_kernel<<<blocks, threads>>>(\n",
        "        A.data_ptr<float>(),\n",
        "        B.data_ptr<float>(),\n",
        "        C.data_ptr<float>(),\n",
        "        m, n, o);\n",
        "\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "    return C;\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "po6dZ2Kvb2KX"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpp_src = \"torch::Tensor mat_mul_col(torch::Tensor A, torch::Tensor B);\"\n",
        "module = load_inline(\n",
        "    name=\"inline_ext_v4\",  # üîÅ Force rebuild by changing name\n",
        "    cuda_sources=[cuda_src_col],\n",
        "    cpp_sources=[cpp_src], # Corrected cpp_sources\n",
        "    functions=['mat_mul_col'],\n",
        "    extra_cuda_cflags=[\"-O2\"],\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3aTlG7T30cD",
        "outputId": "163465ab-ec41-40b5-b00a-48945c37efb9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using /root/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n",
            "The input conditions for extension module inline_ext_v4 have changed. Bumping to version 7 and re-building as inline_ext_v4_v7...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py311_cu124/inline_ext_v4/build.ninja...\n",
            "Building extension module inline_ext_v4_v7...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=inline_ext_v4_v7 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /root/.cache/torch_extensions/py311_cu124/inline_ext_v4/main.cpp -o main.o \n",
            "[2/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=inline_ext_v4_v7 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -O2 -std=c++17 -c /root/.cache/torch_extensions/py311_cu124/inline_ext_v4/cuda.cu -o cuda.cuda.o \n",
            "[3/3] c++ main.o cuda.cuda.o -shared -L/usr/local/lib/python3.11/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o inline_ext_v4_v7.so\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading extension module inline_ext_v4_v7...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "C = module.mat_mul_col(Ac, Bc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QENwX8Z4Vb3",
        "outputId": "70f882e6-fb37-4443-914c-2310620a5c08"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.43 s, sys: 0 ns, total: 5.43 s\n",
            "Wall time: 5.42 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "Yes, based on the execution times you observed (5.8ms for the row-major kernel and 5.4s for the column-major kernel), it appears that the row-major operation was significantly faster in this case."
      ],
      "metadata": {
        "id": "zT2kYUAU9nUS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NxTTe0Ta9LZH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}