{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates creating and loading a custom CUDA extension."
      ],
      "metadata": {
        "id": "OR6y-XQYP8OY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n1LaNKaAIgr2"
      },
      "outputs": [],
      "source": [
        "import torch, os, math, gzip, pickle\n",
        "from pathlib import Path\n",
        "\n",
        "from torch import tensor\n",
        "from torch.utils.cpp_extension import load_inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA setup"
      ],
      "metadata": {
        "id": "ADqetDTyI0QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
        "# Get the CUDA capability of the current device\n",
        "if torch.cuda.is_available():\n",
        "    major, minor = torch.cuda.get_device_capability()\n",
        "    # Set the environment variable with the detected architecture\n",
        "    os.environ['TORCH_CUDA_ARCH_LIST'] = f\"{major}.{minor}\"\n",
        "    print(f\"Setting TORCH_CUDA_ARCH_LIST to: {os.environ['TORCH_CUDA_ARCH_LIST']}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. The warning about TORCH_CUDA_ARCH_LIST is not relevant in this case.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl1aQr4aIlsk",
        "outputId": "8f90ae2e-f278-4930-8b48-55030e6883d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting TORCH_CUDA_ARCH_LIST to: 7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q wurlitzer ninja"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2Bdh6gkI7Eg",
        "outputId": "2f21ffb8-327f-4a96-d242-6f62e17def28"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/422.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m389.1/422.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext wurlitzer"
      ],
      "metadata": {
        "id": "K6GvgQ28I9Yr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cuda(cuda_src, cpp_src, funcs, opt=False, verbose=False):\n",
        "    return load_inline(cuda_sources=[cuda_src], cpp_sources=[cpp_src], functions=funcs,\n",
        "                       extra_cuda_cflags=[\"-O2\"] if opt else [], verbose=verbose, name=\"inline_ext\")"
      ],
      "metadata": {
        "id": "nV4hODOxJBcr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_begin = r'''\n",
        "#include <torch/extension.h>\n",
        "#include <stdio.h>\n",
        "#include <c10/cuda/CUDAException.h>\n",
        "'''"
      ],
      "metadata": {
        "id": "hIXPJ9qvJQdM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src = cuda_begin + r'''\n",
        "__global__ void hello_world_kernel() {\n",
        "    printf(\"Hello World from CUDA!\\n\");\n",
        "}\n",
        "\n",
        "void call_hello_world_kernel() {\n",
        "    hello_world_kernel<<<1, 1>>>();\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "}\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "gsMUDejsJUGg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5b5f8b07-8cb3-4aa8-b2a3-2ddd3878bef2"
      },
      "outputs": [],
      "source": [
        "cpp_src = \"void call_hello_world_kernel();\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06af71ec-3578-4aa9-8949-2cd3e615b534",
        "outputId": "96146cdf-21bf-4054-b658-8282b33e6b21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using /root/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py311_cu124/inline_ext...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py311_cu124/inline_ext/build.ninja...\n",
            "Building extension module inline_ext...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=inline_ext -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /root/.cache/torch_extensions/py311_cu124/inline_ext/main.cpp -o main.o \n",
            "[2/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=inline_ext -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -std=c++17 -c /root/.cache/torch_extensions/py311_cu124/inline_ext/cuda.cu -o cuda.cuda.o \n",
            "[3/3] c++ main.o cuda.cuda.o -shared -L/usr/local/lib/python3.11/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o inline_ext.so\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading extension module inline_ext...\n"
          ]
        }
      ],
      "source": [
        "module = load_cuda(cuda_src, cpp_src, ['call_hello_world_kernel'], verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c07b443-f565-4527-91c6-348f35c6c544",
        "outputId": "69d7bf9e-ae96-451b-abba-02f53736f3e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__spec__',\n",
              " 'call_hello_world_kernel']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "dir(module)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "module.call_hello_world_kernel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfbmnUiDMecV",
        "outputId": "5deab7dc-51db-415b-b4d6-e7a90a19aaf8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World from CUDA!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /root/.cache/torch_extensions/py311_cu124/inline_ext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX66oUnSNOK0",
        "outputId": "1f7349a3-e4cd-4aaa-ded3-792e881c57ce"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build.ninja  cuda.cu  cuda.cuda.o  inline_ext.so  main.cpp  main.o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0dMA3JKPOqQq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}