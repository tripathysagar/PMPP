{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6467e6e",
   "metadata": {},
   "source": [
    "# Ch2 : 1D vector addition\n",
    "\n",
    "> Parallelization of 1D vector addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dc9ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ch2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479c495a",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "  <span>ðŸ“… 09/12/2025</span>\n",
    "  <p align=\"right\">\n",
    "    <a href=\"https://colab.research.google.com/github/tripathysagar/PMPP/blob/main/nbs/02_ch2.ipynb\" target=\"_blank\">\n",
    "        <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "    </a>\n",
    "   </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a3cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%%capture\n",
    "import sys\n",
    "##\n",
    "#If running in colab please switch run time to use GPU for leveraging CUDA.\n",
    "##\n",
    "\n",
    "def is_colab():\n",
    "    return 'google.colab' in sys.modules\n",
    "\n",
    "\n",
    "# Check if running in Google Colab\n",
    "if is_colab():\n",
    "  !git clone https://github.com/tripathysagar/PMPP.git\n",
    "  %cd PMPP\n",
    "  !pip install -e .\n",
    "\n",
    "\n",
    "from PMPP.NumbaSimSetup import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e8167",
   "metadata": {},
   "source": [
    "Setup simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if  is_colab():\n",
    "  assert not is_sim()\n",
    "else:\n",
    "  set_sim()\n",
    "  assert is_sim()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1226bfa",
   "metadata": {},
   "source": [
    "Allocate the memory on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd741f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "N = 10_000\n",
    "a, b = np.random.randn(N), np.random.randn(N)\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e46e7",
   "metadata": {},
   "source": [
    "### Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1fb6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add():\n",
    "    c = np.zeros_like(a)\n",
    "    for i in range(N):\n",
    "        c[i] = a[i] + b[i]\n",
    "    return c\n",
    "\n",
    "c1 = add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0a0162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.69 ms Â± 3.19 ms per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "add()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05789218",
   "metadata": {},
   "source": [
    "{{< video https://www.youtube.com/watch?v=3yxhwooZKw8 >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aebb21",
   "metadata": {},
   "source": [
    "### Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94513424",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1. Memory Allocation (Host â†” Device)\n",
    "\n",
    "For making the sequential loop parallel we have to leverage CUDA's multithread system. The CPU machine is called host while the GPU machine  is known as device. The GPU has its own separate memory (device global memory). To do work on the GPU\n",
    "\n",
    "- **Allocate** memory on the device (`cudaMalloc`)\n",
    "- **Copy** data from host (CPU) to device (GPU) (`cudaMemcpy`)\n",
    "- Run your kernel\n",
    "- **Copy** results back from device to host\n",
    "- **Free** the device memory (`cudaFree`)\n",
    "\n",
    "| CUDA C | Numba CUDA |\n",
    "|--------|------------|\n",
    "| `cudaMalloc` | `cuda.device_array()` |\n",
    "| `cudaMemcpy` (hostâ†’device) | `cuda.to_device()` |\n",
    "| `cudaMemcpy` (deviceâ†’host) | `d_array.copy_to_host()` |\n",
    "| `cudaFree` | Automatic (garbage collected) |\n",
    "\n",
    "\n",
    "Think of it like packing a suitcase: you pack your data, send it to the GPU, do work there, then bring the results back.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u-ZZNeLc7JCJ",
   "metadata": {},
   "source": [
    "### 2. Thread Allocation\n",
    "\n",
    "When a kernel launches, the CUDA runtime creates a **grid of threads** organized in two levels:\n",
    "\n",
    "- **Grid** = array of **blocks**\n",
    "- Each **block** = up to 1024 **threads** (commonly 128-512 for efficiency)\n",
    "- Each thread knows \"who it is\" via built-in variables (`threadIdx.x, blockIdx.x, blockDim.x`)\n",
    "- Formula for each thread its unique global index calculation becomes : `i = blockIdx.x * blockDim.x + threadIdx.x`  \n",
    "\n",
    "Each thread can identify itself using three built-in variables:\n",
    "\n",
    "| Variable | Purpose |\n",
    "|----------|---------|\n",
    "| `threadIdx.x` | Thread's index *within* its block (0, 1, 2, ...) |\n",
    "| `blockIdx.x` | The block's index *within* the grid |\n",
    "| `blockDim.x` | Total number of threads per block |\n",
    "\n",
    "\n",
    "Each thread executes the same code but works on different data (this is called SPMD â€” Single Program, Multiple Data). Continuing the suitcase metaphor each thread uses its unique index to work on one element of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e170606",
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: Thread Organization Pages: 1 -->\n",
       "<svg width=\"305pt\" height=\"265pt\"\n",
       " viewBox=\"0.00 0.00 304.72 264.87\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 260.87)\">\n",
       "<title>Thread Organization</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-260.87 300.72,-260.87 300.72,4 -4,4\"/>\n",
       "<!-- grid -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>grid</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-90 0,-90 0,-54 54,-54 54,-90\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">Grid</text>\n",
       "</g>\n",
       "<!-- b0 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>b0</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"black\" points=\"149,-144 90,-144 90,-108 149,-108 149,-144\"/>\n",
       "<text text-anchor=\"middle\" x=\"119.5\" y=\"-122.3\" font-family=\"Times,serif\" font-size=\"14.00\">Block 0</text>\n",
       "</g>\n",
       "<!-- grid&#45;&gt;b0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>grid&#45;&gt;b0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.18,-87.62C62.55,-92.62 72,-98.26 81.02,-103.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.47,-106.79 89.85,-108.9 83.05,-100.77 79.47,-106.79\"/>\n",
       "</g>\n",
       "<!-- b1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>b1</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"black\" points=\"149,-90 90,-90 90,-54 149,-54 149,-90\"/>\n",
       "<text text-anchor=\"middle\" x=\"119.5\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">Block 1</text>\n",
       "</g>\n",
       "<!-- grid&#45;&gt;b1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>grid&#45;&gt;b1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.18,-72C62.12,-72 71.02,-72 79.61,-72\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.85,-75.5 89.85,-72 79.85,-68.5 79.85,-75.5\"/>\n",
       "</g>\n",
       "<!-- b2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>b2</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"black\" points=\"149,-36 90,-36 90,0 149,0 149,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"119.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Block 2</text>\n",
       "</g>\n",
       "<!-- grid&#45;&gt;b2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>grid&#45;&gt;b2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.18,-56.38C62.55,-51.38 72,-45.74 81.02,-40.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.05,-43.23 89.85,-35.1 79.47,-37.21 83.05,-43.23\"/>\n",
       "</g>\n",
       "<!-- t0 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>t0</title>\n",
       "<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"240.86\" cy=\"-230\" rx=\"45.92\" ry=\"26.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"240.86\" y=\"-233.8\" font-family=\"Times,serif\" font-size=\"14.00\">Thread 0</text>\n",
       "<text text-anchor=\"middle\" x=\"240.86\" y=\"-218.8\" font-family=\"Times,serif\" font-size=\"14.00\">i=0</text>\n",
       "</g>\n",
       "<!-- b0&#45;&gt;t0 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>b0&#45;&gt;t0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M135.64,-144.14C148.1,-158.51 166.65,-178.66 185,-194 189.59,-197.84 194.61,-201.62 199.68,-205.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"197.98,-208.27 208.21,-211.02 201.92,-202.49 197.98,-208.27\"/>\n",
       "</g>\n",
       "<!-- t1 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>t1</title>\n",
       "<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"240.86\" cy=\"-158\" rx=\"45.92\" ry=\"26.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"240.86\" y=\"-161.8\" font-family=\"Times,serif\" font-size=\"14.00\">Thread 1</text>\n",
       "<text text-anchor=\"middle\" x=\"240.86\" y=\"-146.8\" font-family=\"Times,serif\" font-size=\"14.00\">i=1</text>\n",
       "</g>\n",
       "<!-- b0&#45;&gt;t1 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>b0&#45;&gt;t1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M149.09,-133.66C161.08,-136.88 175.39,-140.71 189.06,-144.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"188.3,-147.8 198.86,-147.01 190.11,-141.04 188.3,-147.8\"/>\n",
       "</g>\n",
       "<!-- t2 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>t2</title>\n",
       "<text text-anchor=\"middle\" x=\"240.86\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">...</text>\n",
       "</g>\n",
       "<!-- b0&#45;&gt;t2 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>b0&#45;&gt;t2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M149.09,-118.57C165.46,-114.32 186.17,-108.94 203.67,-104.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"204.75,-107.74 213.54,-101.83 202.99,-100.96 204.75,-107.74\"/>\n",
       "</g>\n",
       "<!-- t255 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>t255</title>\n",
       "<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"240.86\" cy=\"-32\" rx=\"55.72\" ry=\"26.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"240.86\" y=\"-35.8\" font-family=\"Times,serif\" font-size=\"14.00\">Thread 255</text>\n",
       "<text text-anchor=\"middle\" x=\"240.86\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">i=255</text>\n",
       "</g>\n",
       "<!-- b0&#45;&gt;t255 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>b0&#45;&gt;t255</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M139.92,-107.95C155.45,-93.62 176.05,-74.89 185,-68 189.01,-64.91 193.29,-61.8 197.61,-58.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"199.65,-61.63 205.94,-53.11 195.7,-55.85 199.65,-61.63\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|echo: false\n",
    "from graphviz import Digraph\n",
    "\n",
    "g = Digraph('Thread Organization', format='png')\n",
    "g.attr(rankdir='LR')  # Left to Right (horizontal)\n",
    "\n",
    "# Grid\n",
    "g.node('grid', 'Grid', shape='box', style='filled', fillcolor='lightblue')\n",
    "\n",
    "# Blocks\n",
    "g.node('b0', 'Block 0', shape='box', style='filled', fillcolor='lightyellow')\n",
    "g.node('b1', 'Block 1', shape='box', style='filled', fillcolor='lightyellow')\n",
    "g.node('b2', 'Block 2', shape='box', style='filled', fillcolor='lightyellow')\n",
    "\n",
    "# Connect grid to blocks\n",
    "g.edge('grid', 'b0')\n",
    "g.edge('grid', 'b1')\n",
    "g.edge('grid', 'b2')\n",
    "\n",
    "# Threads for Block 0 (just showing a few)\n",
    "g.node('t0', 'Thread 0\\ni=0', shape='ellipse', style='filled', fillcolor='lightgreen')\n",
    "g.node('t1', 'Thread 1\\ni=1', shape='ellipse', style='filled', fillcolor='lightgreen')\n",
    "g.node('t2', '...', shape='plaintext')\n",
    "g.node('t255', 'Thread 255\\ni=255', shape='ellipse', style='filled', fillcolor='lightgreen')\n",
    "\n",
    "g.edge('b0', 't0')\n",
    "g.edge('b0', 't1')\n",
    "g.edge('b0', 't2')\n",
    "g.edge('b0', 't255')\n",
    "\n",
    "g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d10be9",
   "metadata": {},
   "source": [
    "{{< video https://www.youtube.com/watch?v=722WnN2DoYI >}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf683d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 39.0625)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NO_THREADS = 256\n",
    "NO_BLOCKS = N/256\n",
    "NO_THREADS, NO_BLOCKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa3d3a3",
   "metadata": {},
   "source": [
    "The 39.0625 is a floating point number. But it not physically possible we have to allocate block we have to use an int. By rounding down  39 * 256 = 9,984 thread but N = 10,000. We have to use ceil operation for that in the 40th block only 16 threads will be used and the rest will be idle during during computation. CUDA kernels need a bounds check, as 240 idle threads will still run the kernel code, but they'd be accessing memory out of bounds (indices 10,000 to 10,239). One has to be mindful for these idle blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e759f980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "NO_BLOCKS = math.ceil(NO_BLOCKS)\n",
    "NO_BLOCKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YVHSxUUE69gL",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Function qualifiers (how they map to Numba)\n",
    "\n",
    "\n",
    "| CUDA C | Numba | Meaning |\n",
    "|--------|-------|---------|\n",
    "| `__global__` | `@cuda.jit` | Kernel - called from host, runs on device, launches grid |\n",
    "| `__device__` | `@cuda.jit(device=True)` | Device function - called from kernel/device only |\n",
    "| `__host__` | Regular Python function | Runs on CPU |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b936f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit # compile the code to be run on GPU\n",
    "def add_kernel(a, b, c):\n",
    "    #idx = cuda.grid(1)\n",
    "    idx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "\n",
    "    if idx < N and idx >= 0: # Boundary check\n",
    "        c[idx] = a[idx] + b[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7479ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = np.zeros_like(a)\n",
    "#assert c.shape == a.shape\n",
    "\n",
    "#add_kernel[40, 256](a, b, c)\n",
    "device(a), device(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abde7c90",
   "metadata": {},
   "source": [
    "If you are running using cuda sim. The function will run without any error. But there is subtle issue. We have to move data from cpu to gpu i.e. host to device before running the code other wise we will see following error:\n",
    "```text\n",
    "/usr/local/lib/python3.12/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: Grid size 40 will likely result in GPU under-utilization due to low occupancy.\n",
    "  warn(NumbaPerformanceWarning(msg))\n",
    "1.06 ms Â± 110 Âµs per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
    "/usr/local/lib/python3.12/dist-packages/numba_cuda/numba/cuda/cudadrv/devicearray.py:937: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
    "  warn(NumbaPerformanceWarning(msg))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc518ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cuda', 'cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moving data to GPU\n",
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.to_device(b)\n",
    "device(d_a), device(d_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da8e891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# allocating new array for holding computation\n",
    "d_c = cuda.device_array(N, dtype=a.dtype)\n",
    "device(d_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a3ffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: Grid size 40 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.2 Âµs Â± 8.58 Âµs per loop (mean Â± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "add_kernel[40, 256](d_a, d_b, d_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6f0b0",
   "metadata": {},
   "source": [
    "{{< video https://www.youtube.com/watch?v=kpQeVHs2Fec >}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82773889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_close(d_c.copy_to_host(), c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f789a57",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "1. Note: If you are running in the CPU the code will not be faster due to simulation.\n",
    "1. We have been able the converted the sequential loop to a parallel one to leverage GPU multithreads."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
