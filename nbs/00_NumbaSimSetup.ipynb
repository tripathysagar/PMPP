{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9b395a8",
   "metadata": {},
   "source": [
    "# Helper for Numba Simulation\n",
    "\n",
    "> Check if the Numba CUDA simulator is enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaa6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp NumbaSimSetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e6213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8a97de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_sim():\n",
    "    \"\"\"Check if we're running in a simulator by checking the NUMBA_ENABLE_CUDASIM environment variable\"\"\"\n",
    "    return os.environ.get('NUMBA_ENABLE_CUDASIM') == '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900772ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not is_sim()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e0e48f",
   "metadata": {},
   "source": [
    "## Set sim\n",
    "\n",
    "it have to be called befor importing the **cuda**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef3440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def set_sim():\n",
    "    \"\"\" Seting up Numba CUDA simulator\"\"\"\n",
    "    if not is_sim():\n",
    "        os.environ['NUMBA_ENABLE_CUDASIM'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aefdf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_sim()\n",
    "assert is_sim()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a3801",
   "metadata": {},
   "source": [
    "## check if the cuda is available or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd670490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cuda_avail(): \n",
    "    from numba import cuda\n",
    "    return  cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24402975",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cuda_avail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fa2810",
   "metadata": {},
   "source": [
    "## device api mimics **torch.device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e15e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numba.cuda.simulator.cudadrv.devicearray.FakeCUDAArray"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "from numba import cuda\n",
    "d = cuda.device_array(1)\n",
    "type(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5debd448",
   "metadata": {},
   "source": [
    "For a tensor d which is allocated in CUDA\n",
    "```\n",
    "isinstance(d, cuda.cudadrv.devicearray.DeviceNDArray)\n",
    "```\n",
    "\n",
    "So we are going to use `copy_to_host` for checking is the tensor is already present in the device and can be moved to host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d975841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def device(x):\n",
    "    return \"cuda\" if hasattr(x, 'copy_to_host') else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b36f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert device(d) == 'cuda'\n",
    "assert device(d.copy_to_host()) == 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd69b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "\n",
    "def test_close(a, b, tol=1e-4):\n",
    "    return np.allclose(a, b, rtol=tol, atol=tol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1.0, 2.0, 3.0], dtype=np.float32)\n",
    "b = np.array([1.0001, 2.0001, 3.0001], dtype=np.float32)\n",
    "assert test_close(a, b, tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_colab():\n",
    "    \"check is running in colab\"\n",
    "    return 'google.colab' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb906c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not is_colab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6178ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import math\n",
    "def dim(base:float, th:float):\n",
    "    return math.ceil(base/th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8c0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dim(8, 5) == 2\n",
    "assert dim(8, 8) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94069c99",
   "metadata": {},
   "source": [
    "## Performace Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34589e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def perf(warmup=2, iters=20):\n",
    "    def decorator(fn):\n",
    "        @wraps(fn)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            # Warmup runs\n",
    "            for _ in range(warmup):\n",
    "                fn(*args, **kwargs)\n",
    "            \n",
    "            if is_sim():\n",
    "                start = time.perf_counter()\n",
    "                for _ in range(iters):\n",
    "                    result = fn(*args, **kwargs)\n",
    "                elapsed_ms = (time.perf_counter() - start) * 1000 / iters\n",
    "            else:\n",
    "                cuda.synchronize()\n",
    "                \n",
    "                start = cuda.event()\n",
    "                end = cuda.event()\n",
    "                elapsed_ms = 0\n",
    "                \n",
    "                for _ in range(iters):\n",
    "                    start.record()\n",
    "                    result = fn(*args, **kwargs)\n",
    "                    end.record()\n",
    "                    end.synchronize()\n",
    "                    elapsed_ms += cuda.event_elapsed_time(start, end)\n",
    "                \n",
    "                elapsed_ms /= iters\n",
    "            \n",
    "            print(f\"{fn.__name__}: {elapsed_ms:.4f} ms (avg of {iters} runs)\")\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb65a1f7",
   "metadata": {},
   "source": [
    "### CPU-only setup for Numba CUDA simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9cd31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_sleep: 10.6071 ms (avg of 20 runs)\n"
     ]
    }
   ],
   "source": [
    "@perf()\n",
    "def test_sleep():\n",
    "    time.sleep(0.01)  # 10ms sleep\n",
    "\n",
    "test_sleep()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d1a8db",
   "metadata": {},
   "source": [
    "### NumbaSim Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be8564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_add: 1.2910 ms (avg of 10 runs)\n"
     ]
    }
   ],
   "source": [
    "@cuda.jit\n",
    "def add_kernel(a, b, c):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < a.size:\n",
    "        c[idx] = a[idx] + b[idx]\n",
    "\n",
    "# Test data\n",
    "N = 1\n",
    "a = cuda.to_device(np.ones(N, dtype=np.float32))\n",
    "b = cuda.to_device(np.ones(N, dtype=np.float32))\n",
    "c = cuda.device_array(N, dtype=np.float32)\n",
    "\n",
    "@perf(warmup=2, iters=10)\n",
    "def run_add():\n",
    "    add_kernel[1, 1](a, b, c)\n",
    "\n",
    "run_add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d528e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514549d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
